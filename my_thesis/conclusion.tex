Unsupervised learning remains an unsolved, ill-defined problem. However the recent 
advent of deep learning has recast the problem as a representation, or feature learning 
problem. It is not clear what priors, supervision, or cross-sensor modalities are necessary 
for learning a generic representation that can be transferred across multiple problems.
In this work we have mainly focused on the role of time as a source of weak supervision for 
learning visual representations. Indeed it may be necessary to incorporate more sources 
of supervision (e.g. reinforcement learning), or perhaps it is matter of building up the necessary 
model priors (e.g. three-dimensional world) in our models. Another important problem in 
unsupervised feature learning is that of evaluation. How do we evaluate the learned features? 
In this work we have shown that learned features may exhibit properties that they were not 
explicitly trained to satisfy. For example, temporally coherent features are also weakly 
semantically discriminative. Unsurprisingly, however, they are not as discriminative as 
features explicitly trained to discriminate! Thus although they may exhibit useful properties, 
they will never be as good as the features explicitly trained for the task on which they 
are evaluated.      
   
