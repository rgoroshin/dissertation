We have shown that discriminative ConvNet architectures are able to accurately and efficiently estimate the pose of humans in images. While it is not clear if one architecture is applicable to all problem domains, we have never-the-less shown that networks adapted to the problem are able to out-perform existing methods via \emph{domain-specific optimizations}. We have demonstrated such optimizations on two example problem domains:  1) monocular hand-pose recognition from depth images and 2) monocular full body-pose recognition from RGB images.

In Part~\ref{part:one} we presented a novel pipeline for tracking the instantaneous pose of articulable objects from a single depth image. As an application of this pipeline we showed state-of-the-art results for tracking human hands in real-time using commodity hardware. This pipeline leverages the accuracy of offline model-based dataset generation routines in support of a robust real-time ConvNet architecture for feature extraction. We showed that it is possible to use intermediate heat-map features to extract accurate and reliable 3D pose information at interactive frame-rates using inverse kinematics. To build the ConvNet architecture we applied domain-specific applications related to the human hand and since it is possible to use the output of the RDF stage to crop, center and scale the incoming depth image around the hand, we showed that it is possible to use a large fully-connected layer in the network architecture without significant overtraining (since translation invariance need not be learned).

Building upon the results from Part~\ref{part:one}, in Parts~\ref{part:two}, \ref{part:three} and \ref{part:four} we applied an adapted sliding-window based ConvNet architecture to the problem of full-body tracking in monocular RGB images.  For this application we did not have access to a depth image source, however we were able to incorporate connectivity priors to improve the ConvNet architecture as a domain-specific optimization. This was achieved via a novel ConvNet Part-Detector and an MRF inspired Spatial-Model which can be efficiently incorporated into a single learning framework. This new network paradigm significantly outperforms existing architectures on the task of human body pose recognition.  Training and inference of our architecture uses commodity level hardware and runs at close to real-time frame rates, making this technique tractable for a wide variety of application areas.  For future work we expect to further improve upon these results by increasing the complexity and expressiveness of our simple spatial model (especially for unconstrained datasets like LSP and MPII).

In Part~\ref{part:three} we showed that when incorporating both RGB and motion features in our deep ConvNet architecture, our network is able to outperform existing state-of-the-art techniques for the task of human body pose detection in video and improve upon the baseline model of Part~\ref{part:two}. We have also shown that using motion features alone can outperform some traditional algorithms~\cite{Eichner:2009:BAM, yang11cvpr, sapp11eccv}. Our findings suggest that even very simple temporal cues can greatly improve performance with a very minor increase in model complexity. As such, we suggest that future work should place more emphasis on the correct use of motion features.  We would also like to further explore higher level temporal features, potentially via learned spatiotemporal convolution stages and we hope that using a more expressive temporal-spatial model (using motion constraints) will help improve performance significantly.

Though originally developed for the task of classification~\cite{LeCunMNIST}, deep ConvNets have been successfully applied to a multitude of other problems. In classification all variability except the object identity is suppressed. On the other hand, localization tasks such as human body pose estimation often demand a high degree of spatial precision. In Part~\ref{part:four} we presented a domain-specific optimization that is able to efficiently recover the precision lost due to pooling in traditional ConvNet architectures while maintaining the computational benefits of pooling with decimation (or downsampling). We presented a novel cascaded architecture that combined fine and coarse scale convolutional networks, to achieve new state-of-the-art results on the FLIC~\cite{modec} and MPII-human-pose\cite{andriluka14cvpr} datasets.
